\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {ngerman}{}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1}{\ignorespaces Neuron \newline Quelle: simple.wikipedia.org/wiki/File:Neuron.svg\newline Copyright: CC Attribution-Share Alike von Nutzer Dhp1080,\newline bearbeitet}}{5}{figure.caption.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2}{\ignorespaces Ein einfaches neuronales Netz\relax }}{6}{figure.caption.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3}{\ignorespaces Der Plot der Sigmoid Funktion $\sigma (x)=\frac {e^x}{e^x+1}$\relax }}{7}{figure.caption.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4}{\ignorespaces Formel zur Berechnung eines Ausgabevektors aus einem Eingabevektor durch ein Layer Neuronen. \relax }}{8}{figure.caption.5}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {5}{\ignorespaces Die Gleichung f\IeC {\"u}r den durchschnittlichen quadratischen Fehler\relax }}{9}{figure.caption.6}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {6}{\ignorespaces Die Gleichung f\IeC {\"u}r den durchschnittlichen absoluten Fehler\relax }}{9}{figure.caption.7}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {7}{\ignorespaces Der Graph der Kreuzentropie Fehlerfunktion wenn das tats\IeC {\"a}chliche Label 1 ist\relax }}{10}{figure.caption.8}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {8}{\ignorespaces Die Gleichung f\IeC {\"u}r den Kreuzentropiefehler\relax }}{11}{figure.caption.9}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {9}{\ignorespaces Die Gleichung f\IeC {\"u}r den durchschnittlichen absoluten Fehler\relax }}{11}{figure.caption.10}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {10}{\ignorespaces Die Gleichung f\IeC {\"u}r den Gradienten der Fehlerfunktion\relax }}{11}{figure.caption.11}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {11}{\ignorespaces Die Gleichung f\IeC {\"u}r die Anpassung eines einzelnen Parameters\relax }}{12}{figure.caption.12}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {12}{\ignorespaces $\eta $ ist hier zu gro\IeC {\ss } gew\IeC {\"a}hlt\relax }}{12}{figure.caption.13}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {13}{\ignorespaces Eine Verbildlichung der Vorg\IeC {\"a}nge in einem convolutional Layer\newline Aus einer Animation von\newline https://github.com/vdumoulin/conv\_arithmetic/blob/master/README.md Vincent Dumoulin, Francesco Visin - A guide to convolution arithmetic for deep learning (BibTeX)}}{13}{figure.caption.14}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {14}{\ignorespaces Erkennt obere horizontale Kanten\relax }}{14}{figure.caption.15}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {15}{\ignorespaces Erkennt linke vertikale Kanten\relax }}{14}{figure.caption.15}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {16}{\ignorespaces Erkennt untere horizontale Kanten\relax }}{14}{figure.caption.15}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {17}{\ignorespaces Erkennt rechte vertikale Kanten\relax }}{14}{figure.caption.15}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {18}{\ignorespaces Das Beispielbild aus dem Mnist Datensatz\relax }}{14}{figure.caption.16}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {19}{\ignorespaces Die jeweils oben stehenden Filter wurden auf das Beispielbild angewandt.\relax }}{14}{figure.caption.17}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {20}{\ignorespaces Beispiele f\IeC {\"u}r low- mid- und high-level Features in Convolutional Neural Nets\newline Quelle: https://tvirdi.github.io/2017-10-29/cnn/}}{15}{figure.caption.18}% 
