\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {ngerman}{}
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {1}{\ignorespaces Bin\IeC {\"a}rklassifizierung\relax }}{4}{figure.caption.2}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2}{\ignorespaces Regression\relax }}{4}{figure.caption.3}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3}{\ignorespaces Overfitting\relax }}{6}{figure.caption.4}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4}{\ignorespaces Neuron \newline Quelle: simple.wikipedia.org/wiki/File:Neuron.svg\newline Copyright: CC Attribution-Share Alike von Nutzer Dhp1080,\newline bearbeitet}}{7}{figure.caption.5}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {5}{\ignorespaces Ein einfaches neuronales Netz\relax }}{8}{figure.caption.6}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {6}{\ignorespaces Der Plot der Sigmoid Funktion $\sigma (x)=\frac {e^x}{e^x+1}$\relax }}{9}{figure.caption.7}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {7}{\ignorespaces Formel zur Berechnung eines Ausgabevektors aus einem Eingabevektor durch ein Layer Neuronen. \relax }}{10}{figure.caption.8}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {8}{\ignorespaces Die Gleichung f\IeC {\"u}r den durchschnittlichen quadratischen Fehler\relax }}{11}{figure.caption.9}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {9}{\ignorespaces Die Gleichung f\IeC {\"u}r den durchschnittlichen absoluten Fehler\relax }}{12}{figure.caption.10}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {10}{\ignorespaces Der Graph der Kreuzentropie Fehlerfunktion wenn das tats\IeC {\"a}chliche Label 1 ist\relax }}{13}{figure.caption.11}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {11}{\ignorespaces Die Gleichung f\IeC {\"u}r den Kreuzentropiefehler\relax }}{13}{figure.caption.12}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {12}{\ignorespaces Die Gleichung f\IeC {\"u}r den durchschnittlichen absoluten Fehler\relax }}{14}{figure.caption.13}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {13}{\ignorespaces Die Gleichung f\IeC {\"u}r den Gradienten der Fehlerfunktion\relax }}{14}{figure.caption.14}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {14}{\ignorespaces Die Gleichung f\IeC {\"u}r die Anpassung eines einzelnen Parameters\relax }}{14}{figure.caption.15}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {15}{\ignorespaces $\eta $ ist hier zu gro\IeC {\ss } gew\IeC {\"a}hlt\relax }}{15}{figure.caption.16}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {16}{\ignorespaces Eine Verbildlichung der Vorg\IeC {\"a}nge in einem convolutional Layer\newline Aus einer Animation von\newline https://github.com/vdumoulin/conv\_arithmetic/blob/master/README.md Vincent Dumoulin, Francesco Visin - A guide to convolution arithmetic for deep learning (BibTeX)}}{16}{figure.caption.17}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {17}{\ignorespaces Erkennt obere horizontale Kanten\relax }}{17}{figure.caption.18}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {18}{\ignorespaces Erkennt linke vertikale Kanten\relax }}{17}{figure.caption.18}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {19}{\ignorespaces Erkennt untere horizontale Kanten\relax }}{17}{figure.caption.18}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {20}{\ignorespaces Erkennt rechte vertikale Kanten\relax }}{17}{figure.caption.18}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {21}{\ignorespaces Das Beispielbild aus dem Mnist Datensatz\relax }}{17}{figure.caption.19}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {22}{\ignorespaces Die jeweils oben stehenden Filter wurden auf das Beispielbild angewandt.\relax }}{17}{figure.caption.20}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {23}{\ignorespaces Beispiele f\IeC {\"u}r low- mid- und high-level Features in Convolutional Neural Nets\newline Quelle: https://tvirdi.github.io/2017-10-29/cnn/}}{18}{figure.caption.21}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {24}{\ignorespaces Max Pooling mit $2\times 2$ gro\IeC {\ss }en Submatritzen\newline Quelle: https://computersciencewiki.org/index.php/Max-pooling\_/\_Pooling CC BY NC SA Lizenz}}{19}{figure.caption.22}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {25}{\ignorespaces Average Pooling mit $2\times 2$ gro\IeC {\ss }en Submatritzen\newline Aus: Dominguez-Morales, Juan Pedro. (2018). Neuromorphic audio processing through real-time embedded spiking neural networks. Abbildung 33}}{19}{figure.caption.23}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {26}{\ignorespaces Gegen\IeC {\"u}berstellung von Max und Average Pooling\relax }}{20}{figure.caption.24}% 
